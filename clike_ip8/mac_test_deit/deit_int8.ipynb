{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image #处理图像\n",
    "from torch.nn import functional as F    #提供各种函数，如激活函数、池化操作等。\n",
    "from tqdm import tqdm   #显示循环进度条\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### float32数据转int8模块  ##############\n",
    "def float32_to_int8(float32_array): \n",
    "   # 定义量化范围（最小和最大值）\n",
    "    min_val = np.min(float32_array)\n",
    "    max_val = np.max(float32_array)\n",
    "\n",
    "    # 计算缩放因子和零点\n",
    "    scale = (max_val - min_val) / 127.0  # 127 是有符号 int8 的最大值\n",
    "    zero_point = np.round(0 - min_val / scale)\n",
    "\n",
    "    # 使用缩放因子和零点进行量化\n",
    "    int8_array = np.round(float32_array / scale + zero_point).astype(np.int8)\n",
    "\n",
    "    return int8_array   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测时间\n",
    "def bitlet_time(arr_w, arr_a):# arr_w =8x8   arr_a =8x8\n",
    "    \n",
    "    arr_w=float32_to_int8(arr_w)\n",
    "\n",
    "    arr_a=float32_to_int8(arr_a)\n",
    "################### 添加时间测试模块  ##############\n",
    "\n",
    "    mantis = np.empty((8,64))\n",
    "    time = 0\n",
    "\n",
    "    weight_int8 = [\"\"] * 64\n",
    "    active_int8 = [\"\"] * 64\n",
    "    a_sign = [\"\"] * 64\n",
    "    w_sign = [\"\"] * 64\n",
    "    sign   = [\"\"] * 64\n",
    "                            \n",
    "    sign = [\"\"] * 64\n",
    "    for b in range(64): \n",
    "        weight_int8[b] = '{0:08b}'.format(abs(arr_w[b]))\n",
    "        active_int8[b] ='{0:08b}'.format(abs(arr_a[b]))   \n",
    "        \n",
    "        if arr_w[b] >= 0:\n",
    "                w_sign[b] = 0\n",
    "        else:\n",
    "                w_sign[b] = 1\n",
    "\n",
    "        if arr_a[b] >= 0:\n",
    "                a_sign[b] = 0\n",
    "        else:\n",
    "                a_sign[b] = 1\n",
    "                \n",
    "        if w_sign[b]^a_sign[b]:\n",
    "                sign[b] = 1\n",
    "        else:\n",
    "                sign[b] = 0\n",
    "                \n",
    "    w_manti_list = []\n",
    "    a_manti_list = []\n",
    "\n",
    "    for c in range(64):\n",
    "            w_manti_list.append(weight_int8[c])\n",
    "            a_manti_list.append(active_int8[c])\n",
    "\n",
    "\n",
    "    \n",
    "    for i in range(64):\n",
    "        for j in range(8):\n",
    "            mantis[j][i] = w_manti_list[j]\n",
    "\n",
    "\n",
    "    ones = np.empty((8,4))\n",
    "    for i in range(8):\n",
    "        for k in range(4):\n",
    "            one = 0\n",
    "            for j in range(8):\n",
    "                if mantis[i][32+8*k+j]:\n",
    "                    one = one + 1 \n",
    "            ones[i][k] = one\n",
    "\n",
    "    for i in range(8):\n",
    "        for k in range(4):\n",
    "            if (ones[i][k] == 0 or ones[i][k] == 1):\n",
    "                ones[i][k] = k+6\n",
    "            elif (ones[i][k] == 2):\n",
    "                ones[i][k] = k+7\n",
    "            elif (ones[i][k] == (3 or 4)):\n",
    "                ones[i][k] = k+8\n",
    "            else:\n",
    "                ones[i][k] = k+9\n",
    "\n",
    "    for i in range(8):\n",
    "        for k in range(3):\n",
    "            for j in range(3-k):\n",
    "                if(ones[i][k] == ones[i][k+j+1]):\n",
    "                    ones[i][k] = ones[i][k] + 1\n",
    "\n",
    "    for i in range(8):\n",
    "        for k in range(3):\n",
    "            for j in range(3-k):\n",
    "                if(ones[i][k] == ones[i][k+j+1]):\n",
    "                    ones[i][k] = ones[i][k] + 1\n",
    "\n",
    "    for i in range(8):\n",
    "        for k in range(3):\n",
    "            for j in range(3-k):\n",
    "                if(ones[i][k] == ones[i][k+j+1]):\n",
    "                    ones[i][k] = ones[i][k] + 1\n",
    "\n",
    "    time = ones[0][0]\n",
    "    for i in range(8):\n",
    "        for k in range(4):\n",
    "            if(time < ones[i][k]):\n",
    "                time = ones[i][k]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return time+5\n",
    "################### 添加时间测试模块  ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#乘加操作\n",
    "def Mac_64(arr_w, mac_a64):\n",
    "    weight_size = int(arr_w.size/1000)\n",
    "    mac_time = 0\n",
    "\n",
    "    for i in range(0, weight_size, 64):\n",
    "        mac_time = mac_time + bitlet_time(arr_w[i:i+64],mac_a64)\n",
    "    return mac_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积\n",
    "def Conv_33(arr_w, arr_a, w_shape, a_shape, s):\n",
    "\n",
    "    if(arr_w.size % 64 != 0):\n",
    "        arr_w = np.pad(arr_w,(0,(64 - arr_w.size % 64)))\n",
    "\n",
    "    yolo_time = 0\n",
    "    mac_a64 = np.empty(64)\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(0 , (a_shape[3] - 2), s): \n",
    "        print(\"row = \",i)           #row\n",
    "        for j in range(0 , (a_shape[2] - 2), s):        #channel\n",
    "            for k in range(a_shape[1]):        #col\n",
    "                for c in range(3):\n",
    "                    for r in range(3):\n",
    "                        mac_a64[cnt] =  arr_a[i+c,j+r,k]\n",
    "                        cnt = cnt + 1\n",
    "                        if(cnt == 64):\n",
    "                            cnt = 0\n",
    "                            yolo_time = yolo_time + Mac_64(arr_w, mac_a64)\n",
    "            print(j , end = \"|\")\n",
    "\n",
    "    return yolo_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积\n",
    "def Conv_11(arr_w, arr_a, w_shape, a_shape):\n",
    "\n",
    "    if(arr_w.size % 64 != 0):\n",
    "        arr_w = np.pad(arr_w,(0,(64 - arr_w.size % 64)))\n",
    "\n",
    "    yolo_time = 0\n",
    "    mac_a64 = np.empty(64)\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(a_shape[3]):\n",
    "        print(\"row = \",i)            #row\n",
    "        for j in range(a_shape[2]):        #channel\n",
    "            for k in range(a_shape[1]):        #col\n",
    "                mac_a64[cnt] =  arr_a[i,j,k]\n",
    "                cnt = cnt + 1\n",
    "                if(cnt == 64):\n",
    "                    cnt = 0\n",
    "                    yolo_time = yolo_time + Mac_64(arr_w, mac_a64)\n",
    "            print(j , end = \"| \")\n",
    "\n",
    "    return yolo_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image #处理图像\n",
    "from torch.nn import functional as F    #提供各种函数，如激活函数、池化操作等。\n",
    "from tqdm import tqdm   #显示循环进度条\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### 提取weight模块  ##############\n",
    "def extract_onnx_weight(onnx_path):\n",
    "    model = onnx.load(onnx_path)\n",
    "\n",
    "    weights, names = [], []\n",
    "    for t in model.graph.initializer:\n",
    "        weights.append(numpy_helper.to_array(t))\n",
    "        names.append(t.name)\n",
    "        \n",
    "    onnx_weight = dict()\n",
    "    for name, weight in zip(names, weights):\n",
    "        onnx_weight[name] = weight\n",
    "    return onnx_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "47\n",
      "文件不存在。\n",
      "This is layer 0\n",
      "w[layerX]  1219_quantized\n",
      "WEIGHT_NAME = 1219_quantized\n",
      "MED_LAYER_NAME = 193_quantized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33284/246041954.py:93: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  weight = torch.from_numpy(deit_weight[select_weight])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 42.38214898109436\n",
      "This is layer 1\n",
      "w[layerX]  1222_quantized\n",
      "WEIGHT_NAME = 1222_quantized\n",
      "MED_LAYER_NAME = 237_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.064704656600952\n",
      "This is layer 2\n",
      "w[layerX]  1223_quantized\n",
      "WEIGHT_NAME = 1223_quantized\n",
      "MED_LAYER_NAME = 252_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 58.74886131286621\n",
      "This is layer 3\n",
      "w[layerX]  1224_quantized\n",
      "WEIGHT_NAME = 1224_quantized\n",
      "MED_LAYER_NAME = 263_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 60.41621422767639\n",
      "This is layer 4\n",
      "w[layerX]  1225_quantized\n",
      "WEIGHT_NAME = 1225_quantized\n",
      "MED_LAYER_NAME = 278_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 43.66769289970398\n",
      "This is layer 5\n",
      "w[layerX]  1228_quantized\n",
      "WEIGHT_NAME = 1228_quantized\n",
      "MED_LAYER_NAME = 322_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 13.98227572441101\n",
      "This is layer 6\n",
      "w[layerX]  1229_quantized\n",
      "WEIGHT_NAME = 1229_quantized\n",
      "MED_LAYER_NAME = 337_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.022196531295776\n",
      "This is layer 7\n",
      "w[layerX]  1230_quantized\n",
      "WEIGHT_NAME = 1230_quantized\n",
      "MED_LAYER_NAME = 348_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 54.66626262664795\n",
      "This is layer 8\n",
      "w[layerX]  1231_quantized\n",
      "WEIGHT_NAME = 1231_quantized\n",
      "MED_LAYER_NAME = 363_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.61333680152893\n",
      "This is layer 9\n",
      "w[layerX]  1234_quantized\n",
      "WEIGHT_NAME = 1234_quantized\n",
      "MED_LAYER_NAME = 407_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.046881675720215\n",
      "This is layer 10\n",
      "w[layerX]  1235_quantized\n",
      "WEIGHT_NAME = 1235_quantized\n",
      "MED_LAYER_NAME = 422_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.43383598327637\n",
      "This is layer 11\n",
      "w[layerX]  1236_quantized\n",
      "WEIGHT_NAME = 1236_quantized\n",
      "MED_LAYER_NAME = 433_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763173.0\n",
      "44916\n",
      "cp_time 54.73049521446228\n",
      "This is layer 12\n",
      "w[layerX]  1237_quantized\n",
      "WEIGHT_NAME = 1237_quantized\n",
      "MED_LAYER_NAME = 448_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.41044735908508\n",
      "This is layer 13\n",
      "w[layerX]  1240_quantized\n",
      "WEIGHT_NAME = 1240_quantized\n",
      "MED_LAYER_NAME = 492_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.012497663497925\n",
      "This is layer 14\n",
      "w[layerX]  1241_quantized\n",
      "WEIGHT_NAME = 1241_quantized\n",
      "MED_LAYER_NAME = 507_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.12095332145691\n",
      "This is layer 15\n",
      "w[layerX]  1242_quantized\n",
      "WEIGHT_NAME = 1242_quantized\n",
      "MED_LAYER_NAME = 518_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763458.0\n",
      "44916\n",
      "cp_time 54.96205496788025\n",
      "This is layer 16\n",
      "w[layerX]  1243_quantized\n",
      "WEIGHT_NAME = 1243_quantized\n",
      "MED_LAYER_NAME = 533_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 45.794740438461304\n",
      "This is layer 17\n",
      "w[layerX]  1246_quantized\n",
      "WEIGHT_NAME = 1246_quantized\n",
      "MED_LAYER_NAME = 577_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 15.494141340255737\n",
      "This is layer 18\n",
      "w[layerX]  1247_quantized\n",
      "WEIGHT_NAME = 1247_quantized\n",
      "MED_LAYER_NAME = 592_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 59.820578813552856\n",
      "This is layer 19\n",
      "w[layerX]  1248_quantized\n",
      "WEIGHT_NAME = 1248_quantized\n",
      "MED_LAYER_NAME = 603_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.240959882736206\n",
      "This is layer 20\n",
      "w[layerX]  1249_quantized\n",
      "WEIGHT_NAME = 1249_quantized\n",
      "MED_LAYER_NAME = 618_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.35502099990845\n",
      "This is layer 21\n",
      "w[layerX]  1252_quantized\n",
      "WEIGHT_NAME = 1252_quantized\n",
      "MED_LAYER_NAME = 662_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.01337718963623\n",
      "This is layer 22\n",
      "w[layerX]  1253_quantized\n",
      "WEIGHT_NAME = 1253_quantized\n",
      "MED_LAYER_NAME = 677_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.13218307495117\n",
      "This is layer 23\n",
      "w[layerX]  1254_quantized\n",
      "WEIGHT_NAME = 1254_quantized\n",
      "MED_LAYER_NAME = 688_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 54.67706108093262\n",
      "This is layer 24\n",
      "w[layerX]  1255_quantized\n",
      "WEIGHT_NAME = 1255_quantized\n",
      "MED_LAYER_NAME = 703_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.463645935058594\n",
      "This is layer 25\n",
      "w[layerX]  1258_quantized\n",
      "WEIGHT_NAME = 1258_quantized\n",
      "MED_LAYER_NAME = 747_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.135607242584229\n",
      "This is layer 26\n",
      "w[layerX]  1259_quantized\n",
      "WEIGHT_NAME = 1259_quantized\n",
      "MED_LAYER_NAME = 762_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.32376503944397\n",
      "This is layer 27\n",
      "w[layerX]  1260_quantized\n",
      "WEIGHT_NAME = 1260_quantized\n",
      "MED_LAYER_NAME = 773_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 54.969130992889404\n",
      "This is layer 28\n",
      "w[layerX]  1261_quantized\n",
      "WEIGHT_NAME = 1261_quantized\n",
      "MED_LAYER_NAME = 788_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.32343363761902\n",
      "This is layer 29\n",
      "w[layerX]  1264_quantized\n",
      "WEIGHT_NAME = 1264_quantized\n",
      "MED_LAYER_NAME = 832_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.03524398803711\n",
      "This is layer 30\n",
      "w[layerX]  1265_quantized\n",
      "WEIGHT_NAME = 1265_quantized\n",
      "MED_LAYER_NAME = 847_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.23603701591492\n",
      "This is layer 31\n",
      "w[layerX]  1266_quantized\n",
      "WEIGHT_NAME = 1266_quantized\n",
      "MED_LAYER_NAME = 858_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.434685707092285\n",
      "This is layer 32\n",
      "w[layerX]  1267_quantized\n",
      "WEIGHT_NAME = 1267_quantized\n",
      "MED_LAYER_NAME = 873_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.74652552604675\n",
      "This is layer 33\n",
      "w[layerX]  1270_quantized\n",
      "WEIGHT_NAME = 1270_quantized\n",
      "MED_LAYER_NAME = 917_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.101487159729004\n",
      "This is layer 34\n",
      "w[layerX]  1271_quantized\n",
      "WEIGHT_NAME = 1271_quantized\n",
      "MED_LAYER_NAME = 932_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 56.01556086540222\n",
      "This is layer 35\n",
      "w[layerX]  1272_quantized\n",
      "WEIGHT_NAME = 1272_quantized\n",
      "MED_LAYER_NAME = 943_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.17614030838013\n",
      "This is layer 36\n",
      "w[layerX]  1273_quantized\n",
      "WEIGHT_NAME = 1273_quantized\n",
      "MED_LAYER_NAME = 958_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.58981943130493\n",
      "This is layer 37\n",
      "w[layerX]  1276_quantized\n",
      "WEIGHT_NAME = 1276_quantized\n",
      "MED_LAYER_NAME = 1002_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.583685398101807\n",
      "This is layer 38\n",
      "w[layerX]  1277_quantized\n",
      "WEIGHT_NAME = 1277_quantized\n",
      "MED_LAYER_NAME = 1017_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.2787024974823\n",
      "This is layer 39\n",
      "w[layerX]  1278_quantized\n",
      "WEIGHT_NAME = 1278_quantized\n",
      "MED_LAYER_NAME = 1028_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 54.94535279273987\n",
      "This is layer 40\n",
      "w[layerX]  1279_quantized\n",
      "WEIGHT_NAME = 1279_quantized\n",
      "MED_LAYER_NAME = 1043_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.41517901420593\n",
      "This is layer 41\n",
      "w[layerX]  1282_quantized\n",
      "WEIGHT_NAME = 1282_quantized\n",
      "MED_LAYER_NAME = 1087_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.037376642227173\n",
      "This is layer 42\n",
      "w[layerX]  1283_quantized\n",
      "WEIGHT_NAME = 1283_quantized\n",
      "MED_LAYER_NAME = 1102_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.039260149002075\n",
      "This is layer 43\n",
      "w[layerX]  1284_quantized\n",
      "WEIGHT_NAME = 1284_quantized\n",
      "MED_LAYER_NAME = 1113_quantized\n",
      "w_shape: torch.Size([768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 768, 192])\n",
      "a_shape: torch.Size([1, 197, 768])\n",
      "\n",
      "763515.0\n",
      "44916\n",
      "cp_time 55.41070365905762\n",
      "This is layer 44\n",
      "w[layerX]  1285_quantized\n",
      "WEIGHT_NAME = 1285_quantized\n",
      "MED_LAYER_NAME = 1128_quantized\n",
      "w_shape: torch.Size([192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 576])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "572679.0\n",
      "33687\n",
      "cp_time 41.436601877212524\n",
      "This is layer 45\n",
      "w[layerX]  1288_quantized\n",
      "WEIGHT_NAME = 1288_quantized\n",
      "MED_LAYER_NAME = 1172_quantized\n",
      "w_shape: torch.Size([192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 192])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "190893.0\n",
      "11229\n",
      "cp_time 14.029030084609985\n",
      "This is layer 46\n",
      "w[layerX]  1289_quantized\n",
      "WEIGHT_NAME = 1289_quantized\n",
      "MED_LAYER_NAME = 1187_quantized\n",
      "w_shape: torch.Size([192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "after modify:\n",
      "w_shape: torch.Size([1, 192, 768])\n",
      "a_shape: torch.Size([1, 197, 192])\n",
      "\n",
      "763572.0\n",
      "44916\n",
      "cp_time 55.126346588134766\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    IMG_PATH = 'dog.jpg'\n",
    "    ONNX_PATH = 'deit_quant_0519.onnx'\n",
    "    OUT_TXT_PATH = \"data.txt\"\n",
    "\n",
    "    \n",
    "    w = [\"1219_quantized\",\"1222_quantized\", \"1223_quantized\", \"1224_quantized\",\n",
    "         \"1225_quantized\",\"1228_quantized\", \"1229_quantized\", \"1230_quantized\",\n",
    "         \"1231_quantized\",\"1234_quantized\", \"1235_quantized\", \"1236_quantized\", \n",
    "         \"1237_quantized\",\"1240_quantized\", \"1241_quantized\", \"1242_quantized\", \n",
    "         \"1243_quantized\",\"1246_quantized\", \"1247_quantized\", \"1248_quantized\", \n",
    "        \"1249_quantized\", \"1252_quantized\", \"1253_quantized\", \"1254_quantized\",\n",
    "        \"1255_quantized\", \"1258_quantized\",\"1259_quantized\", \"1260_quantized\",\n",
    "        \"1261_quantized\", \"1264_quantized\", \"1265_quantized\", \"1266_quantized\",\n",
    "        \"1267_quantized\",\"1270_quantized\", \"1271_quantized\", \"1272_quantized\",\n",
    "        \"1273_quantized\",\"1276_quantized\", \"1277_quantized\", \"1278_quantized\", \n",
    "\t\t\"1279_quantized\",\"1282_quantized\", \"1283_quantized\", \"1284_quantized\",\n",
    "        \"1285_quantized\",\"1288_quantized\", \"1289_quantized\"]\n",
    "\n",
    "    a = [\"193_quantized\", \"237_quantized\", \"252_quantized\", \"263_quantized\",\n",
    "         \"278_quantized\", \"322_quantized\", \"337_quantized\", \"348_quantized\", \n",
    "         \"363_quantized\",\"407_quantized\", \"422_quantized\", \"433_quantized\",\n",
    "         \"448_quantized\",\"492_quantized\", \"507_quantized\", \"518_quantized\",\n",
    "         \"533_quantized\",\"577_quantized\", \"592_quantized\", \"603_quantized\", \n",
    "\t\t\"618_quantized\",\"662_quantized\", \"677_quantized\", \"688_quantized\",\n",
    "        \"703_quantized\",\"747_quantized\", \"762_quantized\", \"773_quantized\",\n",
    "        \"788_quantized\",\"832_quantized\", \"847_quantized\", \"858_quantized\",\n",
    "        \"873_quantized\",\"917_quantized\", \"932_quantized\", \"943_quantized\",\n",
    "        \"958_quantized\",\"1002_quantized\", \"1017_quantized\", \"1028_quantized\", \n",
    "\t\t\"1043_quantized\",\"1087_quantized\", \"1102_quantized\", \"1113_quantized\",\n",
    "        \"1128_quantized\",\"1172_quantized\",\"1187_quantized\" ]\n",
    "    '''\n",
    "    \n",
    "    w = [\"1219_quantized\", \"226_quantized\", \"225_quantized\", \"1222_quantized\", \"1223_quantized\", \"1224_quantized\", \"1225_quantized\", \"311_quantized\", \"310_quantized\", \"1228_quantized\", \n",
    "        \"1229_quantized\", \"1230_quantized\", \"1231_quantized\", \"396_quantized\", \"395_quantized\", \"1234_quantized\", \"1235_quantized\", \"1236_quantized\", \"1237_quantized\", \"481_quantized\", \n",
    "        \"480_quantized\", \"1240_quantized\", \"1241_quantized\", \"1242_quantized\", \"1243_quantized\", \"566_quantized\", \"565_quantized\", \"1246_quantized\", \"1247_quantized\", \"1248_quantized\", \n",
    "        \"1249_quantized\", \"651_quantized\", \"650_quantized\", \"1252_quantized\", \"1253_quantized\", \"1254_quantized\", \"1255_quantized\", \"736_quantized\", \"735_quantized\", \"1258_quantized\", \n",
    "        \"1259_quantized\", \"1260_quantized\", \"1261_quantized\", \"821_quantized\", \"820_quantized\", \"1264_quantized\", \"1265_quantized\", \"1266_quantized\", \"1267_quantized\", \"906_quantized\", \n",
    "        \"905_quantized\", \"1270_quantized\", \"1271_quantized\", \"1272_quantized\", \"1273_quantized\", \"991_quantized\", \"990_quantized\", \"1276_quantized\", \"1277_quantized\", \"1278_quantized\", \n",
    "        \"1279_quantized\", \"1076_quantized\", \"1075_quantized\", \"1282_quantized\", \"1283_quantized\", \"1284_quantized\", \"1285_quantized\", \"1161_quantized\", \"1160_quantized\", \"1288_quantized\", \n",
    "        \"1289_quantized\" ]\n",
    "    \n",
    "    a = [\"193_quantized\", \"221_quantized\", \"230_quantized\", \"237_quantized\", \"252_quantized\", \"263_quantized\", \"278_quantized\", \"306_quantized\", \"315_quantized\", \"322_quantized\", \n",
    "        \"337_quantized\", \"348_quantized\", \"363_quantized\", \"391_quantized\", \"400_quantized\", \"407_quantized\", \"422_quantized\", \"433_quantized\", \"448_quantized\", \"476_quantized\", \n",
    "        \"485_quantized\", \"492_quantized\", \"507_quantized\", \"518_quantized\", \"533_quantized\", \"561_quantized\", \"570_quantized\", \"577_quantized\", \"592_quantized\", \"603_quantized\", \n",
    "        \"618_quantized\", \"646_quantized\", \"655_quantized\", \"662_quantized\", \"677_quantized\", \"688_quantized\", \"703_quantized\", \"731_quantized\", \"740_quantized\", \"747_quantized\", \n",
    "        \"762_quantized\", \"773_quantized\", \"788_quantized\", \"816_quantized\", \"825_quantized\", \"832_quantized\", \"847_quantized\", \"858_quantized\", \"873_quantized\", \"901_quantized\", \n",
    "        \"910_quantized\", \"917_quantized\", \"932_quantized\", \"943_quantized\", \"958_quantized\", \"986_quantized\", \"995_quantized\", \"1002_quantized\", \"1017_quantized\", \"1028_quantized\", \n",
    "        \"1043_quantized\", \"1071_quantized\", \"1080_quantized\", \"1087_quantized\", \"1102_quantized\", \"1113_quantized\", \"1128_quantized\", \"1156_quantized\", \"1165_quantized\", \"1172_quantized\", \n",
    "        \"1187_quantized\"]\n",
    "    '''\n",
    "    \n",
    "    print(len(w))\n",
    "    print(len(a))\n",
    "    \n",
    "    torch.manual_seed(999)\n",
    "    #打印数组元素的精度设置为10位小数（precision=10）\n",
    "    # 并且不限制数组的打印阈值（threshold=np.inf）\n",
    "    torch.set_printoptions(precision=10,sci_mode=True)\n",
    "    torch.set_printoptions(threshold=np.inf)\n",
    "\n",
    "    # activation\n",
    "    img = Image.open(IMG_PATH).convert(\"RGB\")\n",
    "    img = np.asarray(img, np.float32)/255.0\n",
    "    img= img.transpose(2,0,1).reshape(1,3,224,224)\n",
    "    \n",
    "\n",
    "    # weight\n",
    "    onnx_path_list = [ONNX_PATH]\n",
    "    \n",
    "    out_file = OUT_TXT_PATH\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "        print(\"文件已存在并已删除。\")\n",
    "    else:\n",
    "        print(\"文件不存在。\")\n",
    "\n",
    "    final_time = np.empty((100))\n",
    "    mac_cnt = np.empty((100))\n",
    "\n",
    "    for layerX in range(len(w)):\n",
    "        start_time = time.time()\n",
    "        print(\"This is layer \"+ str(layerX))\n",
    "\n",
    "        print(\"w[layerX] \",w[layerX])\n",
    "        WEIGHT_NAME = str(w[layerX])        #输入w\n",
    "        MED_LAYER_NAME = str(a[layerX])      #输入a\n",
    "        print(\"WEIGHT_NAME = \"+WEIGHT_NAME)\n",
    "        print(\"MED_LAYER_NAME = \"+MED_LAYER_NAME)\n",
    "        deit_weight = extract_onnx_weight(ONNX_PATH)\n",
    "        select_weight = WEIGHT_NAME # \"1138\"\n",
    "        weight = torch.from_numpy(deit_weight[select_weight])\n",
    "        \n",
    "\n",
    "        \n",
    "        # activate\n",
    "        intermediate_layer_name = MED_LAYER_NAME  \n",
    "        model = onnx.load(ONNX_PATH)\n",
    "        for node in model.graph.node:\n",
    "            for output in node.output:\n",
    "                if(output==intermediate_layer_name):\n",
    "                    model.graph.output.extend([onnx.ValueInfoProto(name=output)])\n",
    "        session = onnxruntime.InferenceSession(model.SerializeToString())\n",
    "        # model input\n",
    "        inputs = {'x': img}\n",
    "        # infer\n",
    "        intermediate_layer_output = session.run([intermediate_layer_name], inputs)[0]\n",
    "\n",
    "        act = torch.from_numpy(intermediate_layer_output)\n",
    "        ######################################################################\n",
    "        w_shape = weight.shape \n",
    "        a_shape = act.shape\n",
    "\n",
    "        print('w_shape:',weight.shape)\n",
    "        print('a_shape:',act.shape)\n",
    "\n",
    "        if(weight.ndim == 2):\n",
    "            weight = weight.reshape(1,w_shape[0],w_shape[1])\n",
    "        else:\n",
    "            weight = weight.reshape(w_shape[1],w_shape[2],w_shape[3])\n",
    "      \n",
    "        if(act.ndim == 4):\n",
    "            act = act.reshape(a_shape[1],a_shape[2],a_shape[3])\n",
    "            print(act.shape)\n",
    "        \n",
    "        print('after modify:')\n",
    "        print('w_shape:',weight.shape)\n",
    "        print('a_shape:',act.shape)\n",
    "        w_shape = weight.shape \n",
    "        a_shape = act.shape\n",
    "\n",
    "\n",
    "\n",
    "        a_64 = np.empty(64)\n",
    "        w_64 = np.empty(64)\n",
    "        cnt = 0\n",
    "        layer_time = 0\n",
    "\n",
    "        #print(a_shape[2])\n",
    "        #print(w_shape[1])\n",
    "        assert (a_shape[2] == w_shape[1]), \"error !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!.\"\n",
    "        m_cnt = 0\n",
    "        \n",
    "        #在嵌套的循环中，对权重和激活参数执行一些操作，\n",
    "        # 包括从它们中提取数据，然后将它们传递给 bitlet_time 函数，以计算时间和MAC计数。\n",
    "        for k1 in range(w_shape[0]):\n",
    "            for k2 in range(a_shape[0]):\n",
    "                for k3 in range(a_shape[1]):\n",
    "                    #print(k3,end = \" \")\n",
    "                    for k4 in range(int(w_shape[2]/10)):\n",
    "                        for k5 in range(a_shape[2]):\n",
    "                            a_64[cnt] = act[k1][k3][k5]\n",
    "                            w_64[cnt] = weight[k2][k5][k4]\n",
    "                            cnt = cnt + 1\n",
    "                            \n",
    "                            if(cnt == 64):\n",
    "                                cnt = 0\n",
    "                                m_cnt = m_cnt + 1\n",
    "                                #print(\"a_64 =\",a_64)\n",
    "                                #print(\"w_64 =\",w_64)\n",
    "                                layer_time = layer_time + bitlet_time(a_64,w_64)\n",
    "                print(\"\")\n",
    "        #计算每一对权重和激活参数的时间和MAC计数，\n",
    "        # 并将这些值存储在 final_time 和 mac_cnt 数组中。\n",
    "        \n",
    "        end_time = time.time()\n",
    "        final_time[layerX] = layer_time\n",
    "        mac_cnt[layerX] = m_cnt\n",
    "        print(layer_time)\n",
    "        print(m_cnt)\n",
    "        print(\"cp_time\",end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_time is  26724450.0 total_mac_cnt(64) is  1572060.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_time = 0\n",
    "total_mac_cnt = 0\n",
    "for i in range(71):\n",
    "    total_time = total_time + final_time[i]\n",
    "    total_mac_cnt = total_mac_cnt + mac_cnt[i]\n",
    "print(\"total_time is \", total_time,\"total_mac_cnt(64) is \", total_mac_cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
